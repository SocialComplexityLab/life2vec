
_target_: pytorch_lightning.Trainer
default_root_dir : ${local_path}/logs/
fast_dev_run:  False
min_epochs : 15
max_epochs : 30
track_grad_norm : 2
accumulate_grad_batches: 8
reload_dataloaders_every_n_epochs : 5  
precision: 32
log_every_n_steps : 10
num_sanity_val_steps : False
limit_train_batches : 3000
limit_val_batches : 1000
limit_test_batches: 1000
check_val_every_n_epoch : 3
gradient_clip_val: 1.0
gradient_clip_algorithm: "norm"
detect_anomaly: False ### If you want to check how the gradient is flowing (very slow, use only for debuging)

logger:
  _target_: pytorch_lightning.loggers.TensorBoardLogger
  save_dir: ~/${local_path}/logs/${implementation}
  name: ${name}
  version: ${version}
